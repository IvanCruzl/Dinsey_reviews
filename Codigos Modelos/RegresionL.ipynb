{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re \n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('DisneylandReviews.csv', encoding='ISO-8859-1')\n",
    "df = df[df['Rating'] != 5]\n",
    "\n",
    "# Define sentiment function\n",
    "def sentiment(score):\n",
    "    if score == 4:\n",
    "        return 'Good'\n",
    "    elif score <= 3:\n",
    "        return 'Bad'\n",
    "\n",
    "df['Sentiment'] = df['Rating'].apply(sentiment)\n",
    "\n",
    "# Select relevant columns\n",
    "df = df[['Review_Text', 'Branch', 'Sentiment','Reviewer_Location','Year_Month']]\n",
    "new = df[\"Year_Month\"].str.split(\"-\", n = 1, expand = True)\n",
    "df[\"Year\"]= new[0]\n",
    "df[\"Month\"]= new[1]\n",
    "# Preprocess text\n",
    "stop_words_en = stopwords.words('English')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words_en.append('wa')\n",
    "stop_words_en.append('br')\n",
    "stop_words_en.append('ha')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def limpiar(texto):\n",
    "    res = texto.lower() #Hace en minusculas\n",
    "    res = re.sub(r'[^a-zA-Z0-9\\s]', '', res) #Seleccionas signos de puntuacion, y simbolos que no son alfanumericos\n",
    "    res = word_tokenize(res) #Tokeniza el resultado\n",
    "    res = [lemmatizer.lemmatize(token) for token in res] #Lematiza todo\n",
    "    res = [token for token in res if token not in stop_words_en] #Quitas todas las stopwords y lo guardas en token\n",
    "    res = ' '.join(res) #Como lemmatizer devuelve tupla, se debe de hacer un join\n",
    "    return res\n",
    "\n",
    "df['Texto_limpio'] = df['Review_Text'].apply(limpiar)\n",
    "df.to_csv('df_Binario.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Reviewer_Location</th>\n",
       "      <th>Year_Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Texto_limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you've ever been to Disneyland anywhere you...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Good</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>youve ever disneyland anywhere youll find disn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Its been a while since d last time we visit HK...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Good</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>2019-5</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>since last time visit hk disneyland yet time s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thanks God it wasn   t too hot or too humid wh...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Good</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>thanks god hot humid visiting park otherwise w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HK Disneyland is a great compact park. Unfortu...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Good</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>hk disneyland great compact park unfortunately...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the location is not in the city, took around 1...</td>\n",
       "      <td>Disneyland_HongKong</td>\n",
       "      <td>Good</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2019-4</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>location city took around 1 hour kowlon kid li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review_Text               Branch  \\\n",
       "0  If you've ever been to Disneyland anywhere you...  Disneyland_HongKong   \n",
       "1  Its been a while since d last time we visit HK...  Disneyland_HongKong   \n",
       "2  Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong   \n",
       "3  HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong   \n",
       "4  the location is not in the city, took around 1...  Disneyland_HongKong   \n",
       "\n",
       "  Sentiment     Reviewer_Location Year_Month  Year Month  \\\n",
       "0      Good             Australia     2019-4  2019     4   \n",
       "1      Good           Philippines     2019-5  2019     5   \n",
       "2      Good  United Arab Emirates     2019-4  2019     4   \n",
       "3      Good             Australia     2019-4  2019     4   \n",
       "4      Good        United Kingdom     2019-4  2019     4   \n",
       "\n",
       "                                        Texto_limpio  \n",
       "0  youve ever disneyland anywhere youll find disn...  \n",
       "1  since last time visit hk disneyland yet time s...  \n",
       "2  thanks god hot humid visiting park otherwise w...  \n",
       "3  hk disneyland great compact park unfortunately...  \n",
       "4  location city took around 1 hour kowlon kid li...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df['Texto_limpio']\n",
    "y = df['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, random_state=101)\n",
    "\n",
    "# Vectorize text\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3))\n",
    "X_train_vectorized = tfidf.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for model_SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.77      0.70      0.74      2598\n",
      "        Good       0.78      0.83      0.80      3255\n",
      "\n",
      "    accuracy                           0.78      5853\n",
      "   macro avg       0.77      0.77      0.77      5853\n",
      "weighted avg       0.78      0.78      0.77      5853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "#Classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "X_test_vectorized = tfidf.transform(X_test)\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "# Print the classification report\n",
    "print(\"Classification Report for model_SVM:\")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer3.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and vectorizer\n",
    "joblib.dump(model, 'RegresionL3.joblib')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer3.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
